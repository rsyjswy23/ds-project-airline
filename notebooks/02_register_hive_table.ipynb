{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading small sample from parquet (fast):\n",
      "+----------+---------+-------+----------+-------+----------+-------------+---------+-------+-----------------+--------------+-------+--------+--------+------+----+--------+------+-------+---------+----------------+--------+------------+------------+--------+-------------+-----------------+----+-----+\n",
      "|DayofMonth|DayOfWeek|DepTime|CRSDepTime|ArrTime|CRSArrTime|UniqueCarrier|FlightNum|TailNum|ActualElapsedTime|CRSElapsedTime|AirTime|ArrDelay|DepDelay|Origin|Dest|Distance|TaxiIn|TaxiOut|Cancelled|CancellationCode|Diverted|CarrierDelay|WeatherDelay|NASDelay|SecurityDelay|LateAircraftDelay|Year|Month|\n",
      "+----------+---------+-------+----------+-------+----------+-------------+---------+-------+-----------------+--------------+-------+--------+--------+------+----+--------+------+-------+---------+----------------+--------+------------+------------+--------+-------------+-----------------+----+-----+\n",
      "|        13|        7|   1748|      1800|   1947|      1952|           XE|     2793| N14162|              119|           112|     97|      -5|     -12|   PVD| CLE|     540|     3|     19|        0|            null|       0|           0|           0|       0|            0|                0|2006|    8|\n",
      "|        24|        4|   1422|      1318|   1609|      1455|           XE|     2807| N12921|              107|            97|     79|      74|      64|   IAH| PNS|     489|     3|     25|        0|            null|       0|          64|           0|      10|            0|                0|2006|    8|\n",
      "|        31|        4|   1954|      1950|   2103|      2105|           WN|     2290| N637SW|               69|            75|     59|      -2|       4|   PVD| BWI|     328|     2|      8|        0|            null|       0|           0|           0|       0|            0|                0|2006|    8|\n",
      "|        31|        4|   1503|      1425|   1555|      1522|           YV|     5079| N913FJ|              112|           117|     89|      33|      38|   CLT| STL|     575|     5|     18|        0|            null|       0|          33|           0|       0|            0|                0|2006|    8|\n",
      "|        27|        7|   1135|      1055|   1355|      1315|           WN|     1712|   N341|              140|           140|    115|      40|      40|   BWI| TPA|     842|     3|     22|        0|            null|       0|          40|           0|       0|            0|                0|2006|    8|\n",
      "+----------+---------+-------+----------+-------+----------+-------------+---------+-------+-----------------+--------------+-------+--------+--------+------+----+--------+------+-------+---------+----------------+--------+------------+------------+--------+-------------+-----------------+----+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "Sample count: 1000\n",
      "Inferred schema:\n",
      "root\n",
      " |-- DayofMonth: integer (nullable = true)\n",
      " |-- DayOfWeek: integer (nullable = true)\n",
      " |-- DepTime: string (nullable = true)\n",
      " |-- CRSDepTime: integer (nullable = true)\n",
      " |-- ArrTime: string (nullable = true)\n",
      " |-- CRSArrTime: integer (nullable = true)\n",
      " |-- UniqueCarrier: string (nullable = true)\n",
      " |-- FlightNum: integer (nullable = true)\n",
      " |-- TailNum: string (nullable = true)\n",
      " |-- ActualElapsedTime: string (nullable = true)\n",
      " |-- CRSElapsedTime: string (nullable = true)\n",
      " |-- AirTime: string (nullable = true)\n",
      " |-- ArrDelay: string (nullable = true)\n",
      " |-- DepDelay: string (nullable = true)\n",
      " |-- Origin: string (nullable = true)\n",
      " |-- Dest: string (nullable = true)\n",
      " |-- Distance: integer (nullable = true)\n",
      " |-- TaxiIn: integer (nullable = true)\n",
      " |-- TaxiOut: integer (nullable = true)\n",
      " |-- Cancelled: integer (nullable = true)\n",
      " |-- CancellationCode: string (nullable = true)\n",
      " |-- Diverted: integer (nullable = true)\n",
      " |-- CarrierDelay: integer (nullable = true)\n",
      " |-- WeatherDelay: integer (nullable = true)\n",
      " |-- NASDelay: integer (nullable = true)\n",
      " |-- SecurityDelay: integer (nullable = true)\n",
      " |-- LateAircraftDelay: integer (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Month: integer (nullable = true)\n",
      "\n",
      "Dropping table if exists: flights_2006_staged\n",
      "Creating EXTERNAL table...\n",
      "Table flights_2006_staged created (metadata only).\n",
      "Repairing partitions (if any)...\n",
      "MSCK REPAIR TABLE failed or not needed; continuing.\n",
      "Quick verification: counts by Year (fast):\n",
      "+----+-------+\n",
      "|Year|    cnt|\n",
      "+----+-------+\n",
      "|2006|7141922|\n",
      "+----+-------+\n",
      "\n",
      "Now running full COUNT (may take time)...\n",
      "+-------+\n",
      "|    cnt|\n",
      "+-------+\n",
      "|7141922|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Notebook cell: register_hive_table (paste & run)\n",
    "from pyspark.sql import SparkSession\n",
    "import traceback\n",
    "\n",
    "# Stop any existing Spark session to avoid \"stopped SparkContext\" issues\n",
    "try:\n",
    "    spark.stop()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Create SparkSession with a bit more resources (tune as needed)\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"register_flights_parquet\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .config(\"spark.executor.cores\", \"1\") \\\n",
    "    .config(\"spark.executor.instances\", \"2\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .config(\"spark.sql.warehouse.dir\", \"hdfs://namenode:8020/user/hive/warehouse\") \\\n",
    "    .config(\"spark.hadoop.hive.metastore.uris\", \"thrift://hive-metastore:9083\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "parquet_path = \"hdfs://namenode:8020/data/parquet/flights_2006\"\n",
    "table_name = \"flights_2006_staged\"\n",
    "\n",
    "# 1) Quick sample read to confirm path/permissions\n",
    "try:\n",
    "    print(\"Reading small sample from parquet (fast):\")\n",
    "    sample = spark.read.parquet(parquet_path).limit(1000)\n",
    "    sample.show(5)\n",
    "    print(\"Sample count:\", sample.count())\n",
    "except Exception:\n",
    "    print(\"Failed to read parquet sample — check HDFS path/permissions and that Parquet files exist.\")\n",
    "    traceback.print_exc()\n",
    "    raise\n",
    "\n",
    "# 2) Infer schema and build CREATE EXTERNAL TABLE DDL\n",
    "df = spark.read.parquet(parquet_path)\n",
    "print(\"Inferred schema:\")\n",
    "df.printSchema()\n",
    "\n",
    "type_map = {\n",
    "    \"int\": \"INT\",\n",
    "    \"bigint\": \"BIGINT\",\n",
    "    \"string\": \"STRING\",\n",
    "    \"double\": \"DOUBLE\",\n",
    "    \"float\": \"FLOAT\",\n",
    "    \"boolean\": \"BOOLEAN\",\n",
    "    \"tinyint\": \"TINYINT\",\n",
    "    \"smallint\": \"SMALLINT\",\n",
    "    \"decimal\": \"DECIMAL\"\n",
    "}\n",
    "\n",
    "cols = []\n",
    "for (name, dtype) in df.dtypes:\n",
    "    hive_type = type_map.get(dtype.lower(), \"STRING\")\n",
    "    cols.append(f\"`{name}` {hive_type}\")\n",
    "cols_ddl = \",\\n  \".join(cols)\n",
    "\n",
    "create_stmt = f\"\"\"\n",
    "CREATE EXTERNAL TABLE {table_name} (\n",
    "  {cols_ddl}\n",
    ")\n",
    "STORED AS PARQUET\n",
    "LOCATION '{parquet_path}'\n",
    "\"\"\"\n",
    "\n",
    "# 3) Execute DROP and CREATE as separate statements (Spark expects single statements)\n",
    "try:\n",
    "    print(f\"Dropping table if exists: {table_name}\")\n",
    "    spark.sql(f\"DROP TABLE IF EXISTS {table_name}\")\n",
    "    print(\"Creating EXTERNAL table...\")\n",
    "    spark.sql(create_stmt)\n",
    "    print(f\"Table {table_name} created (metadata only).\")\n",
    "except Exception:\n",
    "    print(\"CREATE TABLE failed — traceback:\")\n",
    "    traceback.print_exc()\n",
    "    raise\n",
    "\n",
    "# 4) (Optional) If data is partitioned by Year/Month on disk, repair partitions\n",
    "# Uncomment the next two lines if you wrote partitions to disk\n",
    "try:\n",
    "    print(\"Repairing partitions (if any)...\")\n",
    "    spark.sql(f\"MSCK REPAIR TABLE {table_name}\")\n",
    "except Exception:\n",
    "    print(\"MSCK REPAIR TABLE failed or not needed; continuing.\")\n",
    "    # continue without raising\n",
    "\n",
    "# 5) Verification: first a quick groupBy (faster), then full COUNT (may take time)\n",
    "try:\n",
    "    print(\"Quick verification: counts by Year (fast):\")\n",
    "    spark.sql(f\"SELECT Year, COUNT(*) AS cnt FROM {table_name} GROUP BY Year ORDER BY Year\").show()\n",
    "    print(\"Now running full COUNT (may take time)...\")\n",
    "    spark.sql(f\"SELECT COUNT(*) AS cnt FROM {table_name}\").show()\n",
    "except Exception:\n",
    "    print(\"Verification failed — full traceback:\")\n",
    "    traceback.print_exc()\n",
    "    # If the COUNT is stuck, cancel from another cell:\n",
    "    # spark.sparkContext.cancelAllJobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.cancelAllJobs()\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
